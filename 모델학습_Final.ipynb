{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bba86dd8-c32b-4dd4-a14c-91f0383cbeb7",
      "metadata": {
        "id": "bba86dd8-c32b-4dd4-a14c-91f0383cbeb7"
      },
      "source": [
        "### 학습률 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "55e2b3bb-df49-4229-80f2-042597a56fb3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55e2b3bb-df49-4229-80f2-042597a56fb3",
        "outputId": "beff2a26-d9ac-45ab-e734-b0e602dca6e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 건물 유형별 모델 학습 시작 ---\n",
            "\n",
            "--- [건물유형 1] 모델 학습 ---\n",
            "[건물유형 1] 모델 R²: 0.9888, MAE: 170.0410, SMAPE: 5.8696%\n",
            "\n",
            "--- [건물유형 2] 모델 학습 ---\n",
            "[건물유형 2] 모델 R²: 0.9969, MAE: 34.8238, SMAPE: 4.5853%\n",
            "\n",
            "--- [건물유형 3] 모델 학습 ---\n",
            "[건물유형 3] 모델 R²: 0.9965, MAE: 47.3084, SMAPE: 2.2138%\n",
            "\n",
            "--- [건물유형 4] 모델 학습 ---\n",
            "[건물유형 4] 모델 R²: 0.9809, MAE: 79.1427, SMAPE: 4.4838%\n",
            "\n",
            "--- [건물유형 5] 모델 학습 ---\n",
            "[건물유형 5] 모델 R²: 0.9984, MAE: 69.7652, SMAPE: 2.3919%\n",
            "\n",
            "--- [건물유형 6] 모델 학습 ---\n",
            "[건물유형 6] 모델 R²: 0.9970, MAE: 94.3043, SMAPE: 4.1338%\n",
            "\n",
            "--- [건물유형 7] 모델 학습 ---\n",
            "[건물유형 7] 모델 R²: 0.9974, MAE: 112.6787, SMAPE: 1.9484%\n",
            "\n",
            "--- [건물유형 8] 모델 학습 ---\n",
            "[건물유형 8] 모델 R²: 0.9977, MAE: 79.6611, SMAPE: 4.0519%\n",
            "\n",
            "--- [건물유형 9] 모델 학습 ---\n",
            "[건물유형 9] 모델 R²: 0.9794, MAE: 80.1657, SMAPE: 3.5292%\n",
            "\n",
            "--- [건물유형 10] 모델 학습 ---\n",
            "[건물유형 10] 모델 R²: 0.9993, MAE: 63.1178, SMAPE: 0.7575%\n",
            "\n",
            "--- 모든 모델 학습 완료 ---\n",
            "저장된 모델 목록 (건물유형 번호): [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "\n",
        "# 1. SMAPE 평가 지표 함수 정의 (기존과 동일)\n",
        "def smape(gt, preds):\n",
        "    \"\"\"\n",
        "    Symmetric Mean Absolute Percentage Error (SMAPE)를 계산합니다.\n",
        "    \"\"\"\n",
        "    gt = np.array(gt)\n",
        "    preds = np.array(preds)\n",
        "    v = 2 * abs(preds - gt) / (abs(preds) + abs(gt) + 1e-8)\n",
        "    score = np.mean(v) * 100\n",
        "    return score\n",
        "\n",
        "# 2. 데이터 로드 (파일 이름만 수정)\n",
        "# '건물유형_번호' 컬럼이 포함된 최종 데이터 파일을 사용합니다.\n",
        "file_path = '/content/drive/MyDrive/DSCover_Guide/modified_dataset_최최종.csv'\n",
        "try:\n",
        "    df = pd.read_csv(file_path)\n",
        "    df['일시'] = pd.to_datetime(df['일시'])\n",
        "except FileNotFoundError:\n",
        "    print(f\"오류: '{file_path}' 파일을 찾을 수 없습니다.\")\n",
        "    exit()\n",
        "\n",
        "# 3. 건물 유형 번호 목록 추출 (수정된 부분)\n",
        "building_type_numbers = sorted(df['건물유형_번호'].unique())\n",
        "\n",
        "# 4. 학습된 모델과 평가 결과를 저장할 딕셔너리 준비 (기존과 동일)\n",
        "trained_models = {}\n",
        "evaluation_results = {}\n",
        "\n",
        "# 5. for 반복문으로 건물 유형별 모델 학습\n",
        "print(\"--- 건물 유형별 모델 학습 시작 ---\")\n",
        "for b_type_num in building_type_numbers:\n",
        "    # NaN 값이 있을 경우 건너뜁니다.\n",
        "    if pd.isna(b_type_num):\n",
        "        continue\n",
        "\n",
        "    # 건물 유형 번호를 정수로 변환하여 사용합니다.\n",
        "    b_type_num = int(b_type_num)\n",
        "    print(f\"\\n--- [건물유형 {b_type_num}] 모델 학습 ---\")\n",
        "\n",
        "    # (1) 데이터 필터링 (수정된 부분)\n",
        "    # '건물유형_번호'를 기준으로 데이터를 필터링합니다.\n",
        "    subset_df = df[df['건물유형_번호'] == b_type_num].copy()\n",
        "\n",
        "    # (2) 피처(X)와 타겟(y) 설정 (수정된 부분)\n",
        "    # 이제 '건물유형_번호' 컬럼도 학습 피처에서 제외해야 합니다.\n",
        "    # 원핫인코딩 컬럼이 있다면 그것도 함께 제거합니다. (안전장치)\n",
        "    building_type_cols = [col for col in df.columns if '건물유형_' in col]\n",
        "    drop_cols = ['전력소비량(kWh)', '일시', '날짜', '건물유형','건물유형_번호'] + building_type_cols\n",
        "\n",
        "    X = subset_df.drop(columns=drop_cols)\n",
        "    y = subset_df['전력소비량(kWh)']\n",
        "\n",
        "    # Lag/Rolling 피처 생성으로 인한 결측치가 있는 행 제거\n",
        "    valid_indices = y.dropna().index\n",
        "    X = X.loc[valid_indices]\n",
        "    y = y.loc[valid_indices]\n",
        "    subset_df = subset_df.loc[valid_indices]\n",
        "\n",
        "    # (3) 훈련/테스트 데이터 분할 (시간 기반 - 기존과 동일)\n",
        "    if X.empty:\n",
        "        print(f\"[건물유형 {b_type_num}] 유효한 학습 데이터가 없습니다.\")\n",
        "        continue\n",
        "\n",
        "    X_train = X[subset_df['일시'] < '2024-08-18']\n",
        "    X_test = X[subset_df['일시'] >= '2024-08-18']\n",
        "    y_train = y[subset_df['일시'] < '2024-08-18']\n",
        "    y_test = y[subset_df['일시'] >= '2024-08-18']\n",
        "\n",
        "    if X_test.empty:\n",
        "        print(f\"[건물유형 {b_type_num}] 테스트 데이터가 없어 평가를 건너뜁니다.\")\n",
        "        continue\n",
        "\n",
        "    # (4) XGBoost 모델 학습 (기존과 동일)\n",
        "    model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=1000, learning_rate=0.05,\n",
        "                             max_depth=5, random_state=42, n_jobs=-1,\n",
        "                             early_stopping_rounds=50)\n",
        "\n",
        "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
        "\n",
        "    # (5) 모델과 평가 결과 저장 (딕셔너리 키를 번호로 저장)\n",
        "    trained_models[b_type_num] = model\n",
        "\n",
        "    predictions = model.predict(X_test)\n",
        "    r2 = r2_score(y_test, predictions)\n",
        "    mae = mean_absolute_error(y_test, predictions)\n",
        "    smape_score = smape(y_test, predictions)\n",
        "\n",
        "    evaluation_results[b_type_num] = {'R2': r2, 'MAE': mae, 'SMAPE': smape_score}\n",
        "\n",
        "    print(f\"[건물유형 {b_type_num}] 모델 R²: {r2:.4f}, MAE: {mae:.4f}, SMAPE: {smape_score:.4f}%\")\n",
        "\n",
        "print(\"\\n--- 모든 모델 학습 완료 ---\")\n",
        "print(\"저장된 모델 목록 (건물유형 번호):\", list(trained_models.keys()))\n",
        "\n",
        "# 예시: 건물유형 2번 모델의 전체 평가 결과 확인\n",
        "# print(\"\\n건물유형 2번 모델 평가 결과:\")\n",
        "# print(evaluation_results[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38c282b7-a5a2-47cb-a9e9-c7f165ab1aef",
      "metadata": {
        "id": "38c282b7-a5a2-47cb-a9e9-c7f165ab1aef"
      },
      "source": [
        "### 학습률 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "904d42b7-8cd9-4002-9854-daa46791285c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "904d42b7-8cd9-4002-9854-daa46791285c",
        "outputId": "66870b68-36cf-4dd0-8376-8452ab4f5f9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- [건물유형 1] 모델 학습 ---\n",
            "[건물유형 1] 모델 R²: 0.9876, MAE: 176.4902, SMAPE: 6.1284%\n",
            "\n",
            "--- [건물유형 2] 모델 학습 ---\n",
            "[건물유형 2] 모델 R²: 0.9969, MAE: 35.5907, SMAPE: 4.7575%\n",
            "\n",
            "--- [건물유형 3] 모델 학습 ---\n",
            "[건물유형 3] 모델 R²: 0.9965, MAE: 46.1583, SMAPE: 2.1293%\n",
            "\n",
            "--- [건물유형 4] 모델 학습 ---\n",
            "[건물유형 4] 모델 R²: 0.9778, MAE: 81.3726, SMAPE: 4.5480%\n",
            "\n",
            "--- [건물유형 5] 모델 학습 ---\n",
            "[건물유형 5] 모델 R²: 0.9985, MAE: 68.7397, SMAPE: 2.3403%\n",
            "\n",
            "--- [건물유형 6] 모델 학습 ---\n",
            "[건물유형 6] 모델 R²: 0.9967, MAE: 93.6638, SMAPE: 3.9750%\n",
            "\n",
            "--- [건물유형 7] 모델 학습 ---\n",
            "[건물유형 7] 모델 R²: 0.9975, MAE: 112.3276, SMAPE: 1.9501%\n",
            "\n",
            "--- [건물유형 8] 모델 학습 ---\n",
            "[건물유형 8] 모델 R²: 0.9977, MAE: 78.6878, SMAPE: 3.9790%\n",
            "\n",
            "--- [건물유형 9] 모델 학습 ---\n",
            "[건물유형 9] 모델 R²: 0.9810, MAE: 75.2801, SMAPE: 3.2906%\n",
            "\n",
            "--- [건물유형 10] 모델 학습 ---\n",
            "[건물유형 10] 모델 R²: 0.9994, MAE: 61.5929, SMAPE: 0.7255%\n",
            "\n",
            "--- 모든 모델 학습 완료 ---\n",
            "저장된 모델 목록 (건물유형 번호): [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
          ]
        }
      ],
      "source": [
        "for b_type_num in building_type_numbers:\n",
        "    # NaN 값이 있을 경우 건너뜁니다.\n",
        "    if pd.isna(b_type_num):\n",
        "        continue\n",
        "\n",
        "    # 건물 유형 번호를 정수로 변환하여 사용합니다.\n",
        "    b_type_num = int(b_type_num)\n",
        "    print(f\"\\n--- [건물유형 {b_type_num}] 모델 학습 ---\")\n",
        "\n",
        "    # (1) 데이터 필터링 (수정된 부분)\n",
        "    # '건물유형_번호'를 기준으로 데이터를 필터링합니다.\n",
        "    subset_df = df[df['건물유형_번호'] == b_type_num].copy()\n",
        "\n",
        "    # (2) 피처(X)와 타겟(y) 설정 (수정된 부분)\n",
        "    # 이제 '건물유형_번호' 컬럼도 학습 피처에서 제외해야 합니다.\n",
        "    # 원핫인코딩 컬럼이 있다면 그것도 함께 제거합니다. (안전장치)\n",
        "    building_type_cols = [col for col in df.columns if '건물유형_' in col]\n",
        "    drop_cols = ['전력소비량(kWh)', '일시', '날짜', '건물유형','건물유형_번호'] + building_type_cols\n",
        "\n",
        "    X = subset_df.drop(columns=drop_cols)\n",
        "    y = subset_df['전력소비량(kWh)']\n",
        "\n",
        "    # Lag/Rolling 피처 생성으로 인한 결측치가 있는 행 제거\n",
        "    valid_indices = y.dropna().index\n",
        "    X = X.loc[valid_indices]\n",
        "    y = y.loc[valid_indices]\n",
        "    subset_df = subset_df.loc[valid_indices]\n",
        "\n",
        "    # (3) 훈련/테스트 데이터 분할 (시간 기반 - 기존과 동일)\n",
        "    if X.empty:\n",
        "        print(f\"[건물유형 {b_type_num}] 유효한 학습 데이터가 없습니다.\")\n",
        "        continue\n",
        "\n",
        "    X_train = X[subset_df['일시'] < '2024-08-18']\n",
        "    X_test = X[subset_df['일시'] >= '2024-08-18']\n",
        "    y_train = y[subset_df['일시'] < '2024-08-18']\n",
        "    y_test = y[subset_df['일시'] >= '2024-08-18']\n",
        "\n",
        "    if X_test.empty:\n",
        "        print(f\"[건물유형 {b_type_num}] 테스트 데이터가 없어 평가를 건너뜁니다.\")\n",
        "        continue\n",
        "\n",
        "    # (4) XGBoost 모델 학습 (기존과 동일)\n",
        "    model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=1000, learning_rate=0.1,\n",
        "                             max_depth=5, random_state=42, n_jobs=-1,\n",
        "                             early_stopping_rounds=50)\n",
        "\n",
        "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
        "\n",
        "    # (5) 모델과 평가 결과 저장 (딕셔너리 키를 번호로 저장)\n",
        "    trained_models[b_type_num] = model\n",
        "\n",
        "    predictions = model.predict(X_test)\n",
        "    r2 = r2_score(y_test, predictions)\n",
        "    mae = mean_absolute_error(y_test, predictions)\n",
        "    smape_score = smape(y_test, predictions)\n",
        "\n",
        "    evaluation_results[b_type_num] = {'R2': r2, 'MAE': mae, 'SMAPE': smape_score}\n",
        "\n",
        "    print(f\"[건물유형 {b_type_num}] 모델 R²: {r2:.4f}, MAE: {mae:.4f}, SMAPE: {smape_score:.4f}%\")\n",
        "\n",
        "print(\"\\n--- 모든 모델 학습 완료 ---\")\n",
        "print(\"저장된 모델 목록 (건물유형 번호):\", list(trained_models.keys()))\n",
        "\n",
        "# 예시: 건물유형 2번 모델의 전체 평가 결과 확인\n",
        "# print(\"\\n건물유형 2번 모델 평가 결과:\")\n",
        "# print(evaluation_results[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "be914481-2ccb-4fa8-bd9d-366b64ae1843",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be914481-2ccb-4fa8-bd9d-366b64ae1843",
        "outputId": "8cba0917-2409-4bcf-a109-2e5521659f94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LightGBM failed: LGBMRegressor.fit() got an unexpected keyword argument 'early_stopping_rounds'\n",
            "\n",
            "Validation results:\n",
            "                model        rmse         mae      wape\n",
            "0            XGBoost  451.321055  242.726658  0.066609\n",
            "1  Baseline_LastWeek  486.620855  207.137190  0.056843\n",
            "\n",
            "Saved:\n",
            " - val_metrics.csv\n",
            " - submission_baseline.csv\n",
            " - submission_model.csv\n",
            "\n",
            "Best model used for submission_model.csv: XGBoost\n",
            "Features used (21): ['cdd18', 'cooling_area_ratio', 'cos_dow', 'cos_hour', 'dow', 'has_ess', 'has_pcs', 'has_solar', 'hdd18', 'hour', 'is_daytime', 'is_weekend'] ...\n"
          ]
        }
      ],
      "source": [
        "# train_eval_submit_final.py\n",
        "# End-to-end: build baseline + XGBoost + LightGBM, evaluate on Aug 1–24, create submissions.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# =========================\n",
        "# Config\n",
        "# =========================\n",
        "PATH_TRAIN = \"/content/drive/MyDrive/DSCover_Guide/modified_dataset_3.csv\"\n",
        "PATH_TEST  = \"/content/drive/MyDrive/DSCover_Guide/test.csv\"\n",
        "PATH_BINFO = \"/content/drive/MyDrive/DSCover_Guide/building_info.csv\"\n",
        "PATH_SUB   = \"/content/drive/MyDrive/DSCover_Guide/sample_submission.csv\"\n",
        "\n",
        "VAL_START = pd.Timestamp(\"2024-08-01 00:00:00\")\n",
        "VAL_END   = pd.Timestamp(\"2024-08-24 23:00:00\")\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "# =========================\n",
        "# Utils\n",
        "# =========================\n",
        "def parse_dt(s: pd.Series) -> pd.Series:\n",
        "    try:\n",
        "        return pd.to_datetime(s, format=\"%Y%m%d %H\")\n",
        "    except Exception:\n",
        "        return pd.to_datetime(s, errors=\"coerce\")\n",
        "\n",
        "def make_unique_cols(cols):\n",
        "    \"\"\"Ensure feature_names are unique for XGBoost.\"\"\"\n",
        "    seen = {}\n",
        "    out = []\n",
        "    for c in cols:\n",
        "        if c not in seen:\n",
        "            seen[c] = 0\n",
        "            out.append(c)\n",
        "        else:\n",
        "            seen[c] += 1\n",
        "            out.append(f\"{c}__dup{seen[c]}\")\n",
        "    return out\n",
        "\n",
        "def rmse(y, p): return float(np.sqrt(np.mean((y - p) ** 2)))\n",
        "def mae(y, p):  return float(np.mean(np.abs(y - p)))\n",
        "def wape(y, p): return float(np.sum(np.abs(y - p)) / (np.sum(np.abs(y)) + 1e-9))\n",
        "\n",
        "def same_hour_last_week_predict(df_target, df_all):\n",
        "    \"\"\"Baseline: predict y(t) = y(t-7d) per building, exact dt alignment.\"\"\"\n",
        "    ref = df_all[[\"건물번호\",\"dt\",\"전력소비량(kWh)\"]].copy()\n",
        "    ref = ref.rename(columns={\"전력소비량(kWh)\":\"y_ref\"})\n",
        "    ref[\"dt_plus_7d\"] = ref[\"dt\"] + pd.Timedelta(days=7)\n",
        "    merged = df_target.merge(\n",
        "        ref[[\"건물번호\",\"dt_plus_7d\",\"y_ref\"]],\n",
        "        left_on=[\"건물번호\",\"dt\"],\n",
        "        right_on=[\"건물번호\",\"dt_plus_7d\"],\n",
        "        how=\"left\",\n",
        "    )\n",
        "    return merged[\"y_ref\"].values\n",
        "\n",
        "# =========================\n",
        "# Load\n",
        "# =========================\n",
        "train = pd.read_csv(PATH_TRAIN)\n",
        "test  = pd.read_csv(PATH_TEST)\n",
        "binfo = pd.read_csv(PATH_BINFO)\n",
        "sub   = pd.read_csv(PATH_SUB)\n",
        "\n",
        "# =========================\n",
        "# Datetime & sort\n",
        "# =========================\n",
        "train[\"dt\"] = parse_dt(train[\"일시\"])\n",
        "test[\"dt\"]  = parse_dt(test[\"일시\"])\n",
        "train.sort_values([\"건물번호\",\"dt\"], inplace=True)\n",
        "test.sort_values([\"건물번호\",\"dt\"], inplace=True)\n",
        "\n",
        "# =========================\n",
        "# Building info cleaning & merge\n",
        "# =========================\n",
        "b = binfo.copy()\n",
        "for c in [\"연면적(m2)\",\"냉방면적(m2)\",\"태양광용량(kW)\",\"ESS저장용량(kWh)\",\"PCS용량(kW)\"]:\n",
        "    if c in b.columns:\n",
        "        b[c] = pd.to_numeric(b[c].replace(\"-\", np.nan), errors=\"coerce\")\n",
        "for c in [\"태양광용량(kW)\",\"ESS저장용량(kWh)\",\"PCS용량(kW)\"]:\n",
        "    if c in b.columns:\n",
        "        b[c] = b[c].fillna(0.0)\n",
        "\n",
        "b[\"cooling_area_ratio\"] = (\n",
        "    b.get(\"냉방면적(m2)\", np.nan) / b.get(\"연면적(m2)\", np.nan)\n",
        ").replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "b[\"has_solar\"] = (b.get(\"태양광용량(kW)\", 0).fillna(0) > 0).astype(\"int8\")\n",
        "b[\"has_ess\"]   = (b.get(\"ESS저장용량(kWh)\",0).fillna(0) > 0).astype(\"int8\")\n",
        "b[\"has_pcs\"]   = (b.get(\"PCS용량(kW)\", 0).fillna(0) > 0).astype(\"int8\")\n",
        "\n",
        "merge_cols = [c for c in [\n",
        "    \"건물번호\",\"건물유형\",\"연면적(m2)\",\"냉방면적(m2)\",\"태양광용량(kW)\",\"ESS저장용량(kWh)\",\"PCS용량(kW)\",\n",
        "    \"cooling_area_ratio\",\"has_solar\",\"has_ess\",\"has_pcs\"\n",
        "] if c in b.columns]\n",
        "\n",
        "train = train.merge(b[merge_cols], on=\"건물번호\", how=\"left\")\n",
        "test  = test.merge(b[merge_cols],  on=\"건물번호\", how=\"left\")\n",
        "\n",
        "# =========================\n",
        "# Drop train-only / leakage cols if present\n",
        "# =========================\n",
        "for c in [\"일조(hr)\",\"일사(MJ/m2)\",\"전력소비량_to_log\"]:\n",
        "    if c in train.columns:\n",
        "        train.drop(columns=c, inplace=True, errors=\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Minimal feature engineering (shared)\n",
        "# =========================\n",
        "for df in (train, test):\n",
        "    df[\"hour\"] = df[\"dt\"].dt.hour.astype(\"int16\")\n",
        "    df[\"dow\"] = df[\"dt\"].dt.dayofweek.astype(\"int16\")\n",
        "    df[\"is_weekend\"] = (df[\"dow\"] >= 5).astype(\"int8\")\n",
        "    df[\"is_daytime\"] = ((df[\"hour\"] >= 6) & (df[\"hour\"] <= 18)).astype(\"int8\")\n",
        "    df[\"sin_hour\"] = np.sin(2*np.pi*df[\"hour\"]/24)\n",
        "    df[\"cos_hour\"] = np.cos(2*np.pi*df[\"hour\"]/24)\n",
        "    df[\"sin_dow\"] = np.sin(2*np.pi*df[\"dow\"]/7)\n",
        "    df[\"cos_dow\"] = np.cos(2*np.pi*df[\"dow\"]/7)\n",
        "    # weather transforms\n",
        "    T = df[\"기온(°C)\"]\n",
        "    df[\"cdd18\"] = (T - 18.0).clip(lower=0)\n",
        "    df[\"hdd18\"] = (18.0 - T).clip(lower=0)\n",
        "    df[\"rain_flag\"] = (df[\"강수량(mm)\"] > 0).astype(\"int8\")\n",
        "    df[\"temp_x_hum\"] = df[\"기온(°C)\"] * df[\"습도(%)\"]\n",
        "\n",
        "# One-hot 건물유형 then drop original\n",
        "if \"건물유형\" in train.columns:\n",
        "    d_tr = pd.get_dummies(train[\"건물유형\"], prefix=\"건물유형\")\n",
        "    d_te = pd.get_dummies(test[\"건물유형\"], prefix=\"건물유형\")\n",
        "    train = pd.concat([train.drop(columns=[\"건물유형\"]), d_tr], axis=1)\n",
        "    test  = pd.concat([test.drop(columns=[\"건물유형\"]),  d_te], axis=1)\n",
        "    # align dummies\n",
        "    for col in set(train.columns) - set(test.columns):\n",
        "        if col.startswith(\"건물유형_\"): test[col] = 0\n",
        "    for col in set(test.columns) - set(train.columns):\n",
        "        if col.startswith(\"건물유형_\"): train[col] = 0\n",
        "\n",
        "# =========================\n",
        "# Validation split\n",
        "# =========================\n",
        "train_fit = train[train[\"dt\"] < VAL_START].copy()\n",
        "val       = train[(train[\"dt\"] >= VAL_START) & (train[\"dt\"] <= VAL_END)].copy()\n",
        "\n",
        "# =========================\n",
        "# Baseline\n",
        "# =========================\n",
        "val_pred_baseline = same_hour_last_week_predict(val, train)\n",
        "results = [{\n",
        "    \"model\": \"Baseline_LastWeek\",\n",
        "    \"rmse\": rmse(val[\"전력소비량(kWh)\"].values, val_pred_baseline),\n",
        "    \"mae\":  mae(val[\"전력소비량(kWh)\"].values, val_pred_baseline),\n",
        "    \"wape\": wape(val[\"전력소비량(kWh)\"].values, val_pred_baseline),\n",
        "}]\n",
        "\n",
        "# =========================\n",
        "# Feature matrix (numeric intersection, unique names)\n",
        "# =========================\n",
        "exclude = {\"전력소비량(kWh)\",\"num_date_time\",\"일시\",\"dt\"}\n",
        "num_train = set(train_fit.select_dtypes(include=[np.number]).columns)\n",
        "num_test  = set(test.select_dtypes(include=[np.number]).columns)\n",
        "X_cols_raw = sorted(list((num_train & num_test) - exclude))\n",
        "X_cols = make_unique_cols(X_cols_raw)\n",
        "\n",
        "# rename to unique names across all splits\n",
        "rename_map = dict(zip(X_cols_raw, X_cols))\n",
        "train_fit = train_fit.rename(columns=rename_map)\n",
        "val       = val.rename(columns=rename_map)\n",
        "train     = train.rename(columns=rename_map)\n",
        "test      = test.rename(columns=rename_map)\n",
        "\n",
        "X_fit = train_fit[X_cols].astype(float)\n",
        "y_fit = train_fit[\"전력소비량(kWh)\"].astype(float).values\n",
        "X_val = val[X_cols].astype(float)\n",
        "y_val = val[\"전력소비량(kWh)\"].astype(float).values\n",
        "X_full = train[X_cols].astype(float)\n",
        "y_full = train[\"전력소비량(kWh)\"].astype(float).values\n",
        "X_test = test[X_cols].astype(float)\n",
        "\n",
        "# =========================\n",
        "# XGBoost\n",
        "# =========================\n",
        "xgb_ok = False\n",
        "try:\n",
        "    from xgboost import XGBRegressor\n",
        "    xgb = XGBRegressor(\n",
        "        n_estimators=1200, learning_rate=0.05, max_depth=8,\n",
        "        subsample=0.9, colsample_bytree=0.9, reg_lambda=1.0,\n",
        "        n_jobs=4, tree_method=\"hist\", random_state=RANDOM_SEED\n",
        "    )\n",
        "    xgb.fit(X_fit, y_fit, eval_set=[(X_val, y_val)], verbose=False)\n",
        "    pred_val_xgb = np.clip(xgb.predict(X_val), 0, None)\n",
        "    results.append({\n",
        "        \"model\":\"XGBoost\",\n",
        "        \"rmse\": rmse(y_val, pred_val_xgb),\n",
        "        \"mae\":  mae(y_val, pred_val_xgb),\n",
        "        \"wape\": wape(y_val, pred_val_xgb),\n",
        "    })\n",
        "    xgb_ok = True\n",
        "except Exception as e:\n",
        "    print(\"XGBoost failed:\", e)\n",
        "\n",
        "# =========================\n",
        "# LightGBM (sklearn API, robust)\n",
        "# =========================\n",
        "lgb_ok = False\n",
        "best_iters = None\n",
        "try:\n",
        "    from lightgbm import LGBMRegressor\n",
        "    lgbm = LGBMRegressor(\n",
        "        objective=\"regression\",\n",
        "        learning_rate=0.05,\n",
        "        num_leaves=127,\n",
        "        subsample=0.9,\n",
        "        colsample_bytree=0.9,\n",
        "        reg_lambda=1.0,\n",
        "        random_state=RANDOM_SEED,\n",
        "        n_estimators=5000,         # cap; ES will stop\n",
        "    )\n",
        "    lgbm.fit(\n",
        "        X_fit, y_fit,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        eval_metric=\"rmse\",\n",
        "        early_stopping_rounds=200,\n",
        "        verbose=False,\n",
        "    )\n",
        "    pred_val_lgb = np.clip(lgbm.predict(X_val), 0, None)\n",
        "    results.append({\n",
        "        \"model\":\"LightGBM\",\n",
        "        \"rmse\": rmse(y_val, pred_val_lgb),\n",
        "        \"mae\":  mae(y_val, pred_val_lgb),\n",
        "        \"wape\": wape(y_val, pred_val_lgb),\n",
        "    })\n",
        "    best_iters = getattr(lgbm, \"best_iteration_\", None)\n",
        "    lgb_ok = True\n",
        "except Exception as e:\n",
        "    print(\"LightGBM failed:\", e)\n",
        "\n",
        "# =========================\n",
        "# Select best & train full\n",
        "# =========================\n",
        "res_df = pd.DataFrame(results).sort_values(\"rmse\").reset_index(drop=True)\n",
        "best = res_df.iloc[0][\"model\"]\n",
        "print(\"\\nValidation results:\\n\", res_df)\n",
        "\n",
        "# baseline for test\n",
        "test_pred_baseline = np.clip(same_hour_last_week_predict(test, train), 0, None)\n",
        "\n",
        "if best == \"XGBoost\" and xgb_ok:\n",
        "    xgb_full = XGBRegressor(\n",
        "        n_estimators=1200, learning_rate=0.05, max_depth=8,\n",
        "        subsample=0.9, colsample_bytree=0.9, reg_lambda=1.0,\n",
        "        n_jobs=4, tree_method=\"hist\", random_state=RANDOM_SEED\n",
        "    )\n",
        "    xgb_full.fit(X_full, y_full, verbose=False)\n",
        "    test_pred_model = np.clip(xgb_full.predict(X_test), 0, None)\n",
        "elif best == \"LightGBM\" and lgb_ok:\n",
        "    final_estimators = int(best_iters) if (best_iters is not None and best_iters > 0) else 1200\n",
        "    lgbm_full = LGBMRegressor(\n",
        "        objective=\"regression\",\n",
        "        learning_rate=0.05,\n",
        "        num_leaves=127,\n",
        "        subsample=0.9,\n",
        "        colsample_bytree=0.9,\n",
        "        reg_lambda=1.0,\n",
        "        random_state=RANDOM_SEED,\n",
        "        n_estimators=final_estimators,\n",
        "    )\n",
        "    lgbm_full.fit(X_full, y_full, verbose=False)\n",
        "    test_pred_model = np.clip(lgbm_full.predict(X_test), 0, None)\n",
        "else:\n",
        "    best = \"Baseline_LastWeek\"\n",
        "    test_pred_model = test_pred_baseline.copy()\n",
        "\n",
        "# Non-negative clamp (already clipped) — keep anyway for safety\n",
        "test_pred_model = np.clip(test_pred_model, 0, None)\n",
        "\n",
        "# =========================\n",
        "# Save outputs\n",
        "# =========================\n",
        "out_dir = Path(\".\")\n",
        "res_df.to_csv(out_dir / \"val_metrics.csv\", index=False)\n",
        "\n",
        "sub_base = sub.copy()\n",
        "sub_base[\"answer\"] = test_pred_baseline.astype(float)\n",
        "sub_base.to_csv(out_dir / \"submission_baseline.csv\", index=False)\n",
        "\n",
        "sub_model = sub.copy()\n",
        "sub_model[\"answer\"] = test_pred_model.astype(float)\n",
        "sub_model.to_csv(out_dir / \"submission_model.csv\", index=False)\n",
        "\n",
        "print(\"\\nSaved:\")\n",
        "print(\" - val_metrics.csv\")\n",
        "print(\" - submission_baseline.csv\")\n",
        "print(\" - submission_model.csv\")\n",
        "print(f\"\\nBest model used for submission_model.csv: {best}\")\n",
        "print(f\"Features used ({len(X_cols)}): {X_cols[:12]} ...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cz9KQ_UUQdjU",
        "outputId": "12c61ff0-d877-4670-cc87-2776c7dc9034"
      },
      "id": "Cz9KQ_UUQdjU",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}